{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "\n",
    "In this project, you will perform a logistic regression on the admissions data we've been working with in projects 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige\n",
      "0      0  380.0  3.61       3.0\n",
      "1      1  660.0  3.67       3.0\n",
      "2      1  800.0  4.00       1.0\n",
      "3      1  640.0  3.19       4.0\n",
      "4      0  520.0  2.93       4.0\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"../assets/admissions.csv\")\n",
    "df = df_raw.dropna() \n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Frequency Tables\n",
    "\n",
    "#### 1. Let's create a frequency table of our variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397\n"
     ]
    }
   ],
   "source": [
    "# frequency table for prestige and whether or not someone was admitted\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1.   61.]\n",
      " [   2.  148.]\n",
      " [   3.  121.]\n",
      " [   4.   67.]]\n"
     ]
    }
   ],
   "source": [
    "instance,count= np.unique(df.prestige, return_counts=True)\n",
    "print np.asarray((instance,count)).T\n",
    "# this is one way of doing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.,   61.],\n",
       "       [   2.,  148.],\n",
       "       [   3.,  121.],\n",
       "       [   4.,   67.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import itemfreq\n",
    "itemfreq(df.prestige)\n",
    "# this is another way of doing this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     # of instances of prestige variable\n",
      "1.0                                   61\n",
      "2.0                                  148\n",
      "3.0                                  121\n",
      "4.0                                   67\n"
     ]
    }
   ],
   "source": [
    "table=pd.DataFrame(count,index=instance, columns=['# of instances of prestige variable'])\n",
    "print table\n",
    "# this creates an actual table, nicely labeled, as opposed to just an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  # of applicants in each category\n",
      "Not admitted (0)                               271\n",
      "Admitted (1)                                   126\n"
     ]
    }
   ],
   "source": [
    "instance2,count2=np.unique(df.admit, return_counts=True)\n",
    "table2=pd.DataFrame(count2,index=['Not admitted (0)','Admitted (1)'], columns=['# of applicants in each category'])\n",
    "print table2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Return of dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Create class or dummy variables for prestige "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Prestige_1  Prestige_2  Prestige_3  Prestige_4\n",
      "0           0.0         0.0         1.0         0.0\n",
      "1           0.0         0.0         1.0         0.0\n",
      "2           1.0         0.0         0.0         0.0\n",
      "3           0.0         0.0         0.0         1.0\n",
      "4           0.0         0.0         0.0         1.0\n",
      "5           0.0         1.0         0.0         0.0\n",
      "6           1.0         0.0         0.0         0.0\n",
      "7           0.0         1.0         0.0         0.0\n",
      "8           0.0         0.0         1.0         0.0\n",
      "9           0.0         1.0         0.0         0.0\n",
      "10          0.0         0.0         0.0         1.0\n",
      "11          1.0         0.0         0.0         0.0\n",
      "12          1.0         0.0         0.0         0.0\n",
      "13          0.0         1.0         0.0         0.0\n",
      "14          1.0         0.0         0.0         0.0\n",
      "15          0.0         0.0         1.0         0.0\n",
      "16          0.0         0.0         0.0         1.0\n",
      "17          0.0         0.0         1.0         0.0\n",
      "18          0.0         1.0         0.0         0.0\n",
      "19          1.0         0.0         0.0         0.0\n",
      "20          0.0         0.0         1.0         0.0\n",
      "21          0.0         1.0         0.0         0.0\n",
      "22          0.0         0.0         0.0         1.0\n",
      "23          0.0         0.0         0.0         1.0\n",
      "24          0.0         1.0         0.0         0.0\n",
      "25          1.0         0.0         0.0         0.0\n",
      "26          1.0         0.0         0.0         0.0\n",
      "27          0.0         0.0         0.0         1.0\n",
      "28          0.0         1.0         0.0         0.0\n",
      "29          1.0         0.0         0.0         0.0\n",
      "..          ...         ...         ...         ...\n",
      "370         0.0         1.0         0.0         0.0\n",
      "371         0.0         0.0         1.0         0.0\n",
      "372         1.0         0.0         0.0         0.0\n",
      "373         1.0         0.0         0.0         0.0\n",
      "374         0.0         1.0         0.0         0.0\n",
      "375         0.0         0.0         0.0         1.0\n",
      "376         0.0         1.0         0.0         0.0\n",
      "377         0.0         1.0         0.0         0.0\n",
      "378         0.0         0.0         1.0         0.0\n",
      "379         0.0         1.0         0.0         0.0\n",
      "380         0.0         1.0         0.0         0.0\n",
      "381         0.0         1.0         0.0         0.0\n",
      "382         0.0         1.0         0.0         0.0\n",
      "383         1.0         0.0         0.0         0.0\n",
      "384         0.0         1.0         0.0         0.0\n",
      "385         1.0         0.0         0.0         0.0\n",
      "386         0.0         1.0         0.0         0.0\n",
      "387         0.0         1.0         0.0         0.0\n",
      "388         0.0         1.0         0.0         0.0\n",
      "389         0.0         1.0         0.0         0.0\n",
      "390         0.0         1.0         0.0         0.0\n",
      "391         0.0         1.0         0.0         0.0\n",
      "392         0.0         0.0         1.0         0.0\n",
      "393         0.0         1.0         0.0         0.0\n",
      "394         0.0         0.0         1.0         0.0\n",
      "395         0.0         1.0         0.0         0.0\n",
      "396         0.0         0.0         1.0         0.0\n",
      "397         0.0         1.0         0.0         0.0\n",
      "398         0.0         1.0         0.0         0.0\n",
      "399         0.0         0.0         1.0         0.0\n",
      "\n",
      "[397 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "prestige_dummies=pd.get_dummies(df.prestige)\n",
    "prestige_dummies.columns=['Prestige_1',\"Prestige_2\",\"Prestige_3\",'Prestige_4']\n",
    "print prestige_dummies\n",
    "# Have created the dummy variables and put them in their own separate dataframe named prestige_dummies- will be able to join this to any other df's later...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 When modeling our class variables, how many do we need? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Since there are 4 outcomes, we need to use 3 of them in any analysis we conduct, since whenever a categorical variable with n outcomes is encoded into multiple 1/0 dummy variables, n-1 of them need to be included in analysis (since by definition knowing the value of 3 of the variables also makes the 4th known, and therefore incorporating all 4 into analysis would be redundant and skew any analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Hand calculating odds ratios\n",
    "\n",
    "Develop your intuition about expected outcomes by hand calculating odds ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  Prestige_1\n",
      "0      0  380.0  3.61         0.0\n",
      "1      1  660.0  3.67         0.0\n",
      "2      1  800.0  4.00         1.0\n",
      "3      1  640.0  3.19         0.0\n",
      "4      0  520.0  2.93         0.0\n"
     ]
    }
   ],
   "source": [
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "handCalc = df[cols_to_keep].join(prestige_dummies['Prestige_1'])\n",
    "print handCalc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prestige_1  0.0  1.0\n",
      "admit               \n",
      "0           243   28\n",
      "1            93   33\n"
     ]
    }
   ],
   "source": [
    "#crosstab prestige 1 admission \n",
    "# frequency table cutting prestige and whether or not someone was admitted\n",
    "crosstab=pd.crosstab(handCalc.admit,handCalc.Prestige_1)\n",
    "print crosstab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Use the cross tab above to calculate the odds of being admitted to grad school if you attended a #1 ranked college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17857142857\n"
     ]
    }
   ],
   "source": [
    "# the odds would be 33:28, since it's probability of admittance divided by probability of non-admittance\n",
    "odds1=float(crosstab[1][1])/float(crosstab[1][0])\n",
    "print odds1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The odds would be equal to ~ 1.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Now calculate the odds of admission if you did not attend a #1 ranked college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.382716049383\n"
     ]
    }
   ],
   "source": [
    "#the odds would be 93:243\n",
    "odds2= float(crosstab[0][1])/float(crosstab[0][0])\n",
    "print odds2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Calculate the odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.07949308756\n"
     ]
    }
   ],
   "source": [
    "# the odds ratio would be the division of the odds of being admitted if attending #1 divided by the odds of being admitted if NOT attending a #1\n",
    "print odds1/odds2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The odds ratio is ~3.08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Write this finding in a sentence: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The odds of being admitted for a student that attended a top tier (Prestige=1) school are ~3.08 larger than the odds for a student that did not attend a top tier (Prestige=1) school\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Print the cross tab for prestige_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prestige_4  0.0  1.0\n",
      "admit               \n",
      "0           216   55\n",
      "1           114   12\n"
     ]
    }
   ],
   "source": [
    "handCalc=handCalc.join(prestige_dummies['Prestige_4'])\n",
    "crosstab2=pd.crosstab(handCalc.admit,handCalc.Prestige_4)\n",
    "print crosstab2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Calculate the OR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.413397129187\n"
     ]
    }
   ],
   "source": [
    "odds_1=float(crosstab2[1][1])/float(crosstab2[1][0])\n",
    "odds_2=float(crosstab2[0][1])/float(crosstab2[0][0])\n",
    "print odds_1/odds_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Write this finding in a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The odds of being admitted for a student that attended the least prestigious category of school (Prestige=4) are ~.41 (e.g. significantly lower) than the odds for a student that attended any schools that were more prestigious (Prestige 1-3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  Prestige_1  Prestige_2  Prestige_3\n",
      "0      0  380.0  3.61         0.0         0.0         1.0\n",
      "1      1  660.0  3.67         0.0         0.0         1.0\n",
      "2      1  800.0  4.00         1.0         0.0         0.0\n",
      "3      1  640.0  3.19         0.0         0.0         0.0\n",
      "4      0  520.0  2.93         0.0         0.0         0.0\n"
     ]
    }
   ],
   "source": [
    "# create a clean data frame for the regression\n",
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "data = df[cols_to_keep].join(prestige_dummies['Prestige_1'])\n",
    "data=data.join(prestige_dummies.Prestige_2)\n",
    "data=data.join(prestige_dummies.Prestige_3)\n",
    "\n",
    "print data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to add a constant term for our Logistic Regression. The statsmodels function we're going to be using requires that intercepts/constants are specified explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  Prestige_1  Prestige_2  Prestige_3  intercept\n",
      "0      0  380.0  3.61         0.0         0.0         1.0        1.0\n",
      "1      1  660.0  3.67         0.0         0.0         1.0        1.0\n",
      "2      1  800.0  4.00         1.0         0.0         0.0        1.0\n",
      "3      1  640.0  3.19         0.0         0.0         0.0        1.0\n",
      "4      0  520.0  2.93         0.0         0.0         0.0        1.0\n"
     ]
    }
   ],
   "source": [
    "# manually add the intercept\n",
    "data['intercept'] = 1.0\n",
    "print data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Set the covariates to a variable called train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cols=data[['gre','gpa','Prestige_1','Prestige_2','Prestige_3','intercept']]\n",
    "admit=data.admit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=sm.Logit(data.admit,train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573854\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "model_fit=model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# above was the sm version- want to double check results against the sklearn version\n",
    "from sklearn import tree, cross_validation, linear_model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[[  1.58889206e-03   1.84630696e-04   1.16761197e+00   5.26947989e-01\n",
      "   -3.80822681e-02  -2.07018745e+00]]\n"
     ]
    }
   ],
   "source": [
    "test_model=linear_model.LogisticRegression(fit_intercept=False)\n",
    "fittedmodel=test_model.fit(train_cols,admit)\n",
    "print fittedmodel.intercept_\n",
    "print fittedmodel.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# open question why this would give different results- presume it has something to do w/ the way the intercept is handled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Print the summary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  admit   No. Observations:                  397\n",
      "Model:                          Logit   Df Residuals:                      391\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Sat, 23 Jul 2016   Pseudo R-squ.:                 0.08166\n",
      "Time:                        20:31:00   Log-Likelihood:                -227.82\n",
      "converged:                       True   LL-Null:                       -248.08\n",
      "                                        LLR p-value:                 1.176e-07\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "gre            0.0022      0.001      2.028      0.043      7.44e-05     0.004\n",
      "gpa            0.7793      0.333      2.344      0.019         0.128     1.431\n",
      "Prestige_1     1.5534      0.417      3.721      0.000         0.735     2.372\n",
      "Prestige_2     0.8733      0.367      2.378      0.017         0.153     1.593\n",
      "Prestige_3     0.2147      0.393      0.547      0.584        -0.555     0.984\n",
      "intercept     -5.4303      1.140     -4.764      0.000        -7.664    -3.196\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print model_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Coefficient\n",
      "gre            0.002218\n",
      "gpa            0.779337\n",
      "Prestige_1     1.553411\n",
      "Prestige_2     0.873274\n",
      "Prestige_3     0.214733\n",
      "intercept     -5.430265\n"
     ]
    }
   ],
   "source": [
    "oddsratios=model_fit.params\n",
    "oddsratios=pd.DataFrame(oddsratios)\n",
    "oddsratios.rename(columns={0:'Coefficient'},inplace=True)\n",
    "print oddsratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            CI- Lower  CI- Upper\n",
      "gre          0.000074   0.004362\n",
      "gpa          0.127619   1.431056\n",
      "Prestige_1   0.735197   2.371624\n",
      "Prestige_2   0.153432   1.593115\n",
      "Prestige_3  -0.554669   0.984135\n",
      "intercept   -7.664377  -3.196152\n"
     ]
    }
   ],
   "source": [
    "confint=pd.DataFrame(model_fit.conf_int())\n",
    "confint.rename(columns={0:\"CI- Lower\",1:'CI- Upper'},inplace=True)\n",
    "print confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oddsratios=oddsratios.join(confint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Coefficient  CI- Lower  CI- Upper OR\n",
      "gre            0.002218   0.000074   0.004362   \n",
      "gpa            0.779337   0.127619   1.431056   \n",
      "Prestige_1     1.553411   0.735197   2.371624   \n",
      "Prestige_2     0.873274   0.153432   1.593115   \n",
      "Prestige_3     0.214733  -0.554669   0.984135   \n",
      "intercept     -5.430265  -7.664377  -3.196152   \n"
     ]
    }
   ],
   "source": [
    "oddsratios['OR']=''\n",
    "print oddsratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_OR(row):\n",
    "    return np.exp(row.Coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oddsratios['OR']=oddsratios.apply(calc_OR,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Calculate the odds ratios of the coeffiencents and their 95% CI intervals\n",
    "\n",
    "hint 1: np.exp(X)\n",
    "\n",
    "hint 2: conf['OR'] = params\n",
    "        \n",
    "           conf.columns = ['2.5%', '97.5%', 'OR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Coefficient  CI- Lower  CI- Upper        OR\n",
      "gre            0.002218   0.000074   0.004362  1.002221\n",
      "gpa            0.779337   0.127619   1.431056  2.180027\n",
      "Prestige_1     1.553411   0.735197   2.371624  4.727566\n",
      "Prestige_2     0.873274   0.153432   1.593115  2.394738\n",
      "Prestige_3     0.214733  -0.554669   0.984135  1.239531\n",
      "intercept     -5.430265  -7.664377  -3.196152  0.004382\n"
     ]
    }
   ],
   "source": [
    "print oddsratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Interpret the OR of Prestige_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The likelihood of admittance for someone that attended a prestige 2 school (2nd tier) is ~2.39 times greater than the likelihood of admittance for someone that did not attend a prestige 2 school"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 Interpret the OR of GPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: An increase in GPA by one point increases the likelihood of admittance by a factor of 2.18, relative to the likelihood of admittance without an increase in GPA by one point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Predicted probablities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a way of evaluating our classifier, we're going to recreate the dataset with every logical combination of input values. This will allow us to see how the predicted probability of admission increases/decreases across different variables. First we're going to generate the combinations using a helper function called cartesian (above).\n",
    "\n",
    "We're going to use np.linspace to create a range of values for \"gre\" and \"gpa\". This creates a range of linearly spaced values from a specified min and maximum value--in our case just the min/max observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cartesian(arrays, out=None):\n",
    "    \"\"\"\n",
    "    Generate a cartesian product of input arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    arrays : list of array-like\n",
    "        1-D arrays to form the cartesian product of.\n",
    "    out : ndarray\n",
    "        Array to place the cartesian product in.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        2-D array of shape (M, len(arrays)) containing cartesian products\n",
    "        formed of input arrays.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cartesian(([1, 2, 3], [4, 5], [6, 7]))\n",
    "    array([[1, 4, 6],\n",
    "           [1, 4, 7],\n",
    "           [1, 5, 6],\n",
    "           [1, 5, 7],\n",
    "           [2, 4, 6],\n",
    "           [2, 4, 7],\n",
    "           [2, 5, 6],\n",
    "           [2, 5, 7],\n",
    "           [3, 4, 6],\n",
    "           [3, 4, 7],\n",
    "           [3, 5, 6],\n",
    "           [3, 5, 7]])\n",
    "    \"\"\"\n",
    "\n",
    "    arrays = [np.asarray(x) for x in arrays]\n",
    "    dtype = arrays[0].dtype\n",
    "\n",
    "    n = np.prod([x.size for x in arrays])\n",
    "    if out is None:\n",
    "        out = np.zeros([n, len(arrays)], dtype=dtype)\n",
    "\n",
    "    m = n / arrays[0].size\n",
    "    out[:,0] = np.repeat(arrays[0], m)\n",
    "    if arrays[1:]:\n",
    "        cartesian(arrays[1:], out=out[0:m,1:])\n",
    "        for j in xrange(1, arrays[0].size):\n",
    "            out[j*m:(j+1)*m,1:] = out[0:m,1:]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 220.          284.44444444  348.88888889  413.33333333  477.77777778\n",
      "  542.22222222  606.66666667  671.11111111  735.55555556  800.        ]\n",
      "[ 2.26        2.45333333  2.64666667  2.84        3.03333333  3.22666667\n",
      "  3.42        3.61333333  3.80666667  4.        ]\n"
     ]
    }
   ],
   "source": [
    "# instead of generating all possible values of GRE and GPA, we're going\n",
    "# to use an evenly spaced range of 10 values from the min to the max \n",
    "gres = np.linspace(data['gre'].min(), data['gre'].max(), 10)\n",
    "print gres\n",
    "# array([ 220.        ,  284.44444444,  348.88888889,  413.33333333,\n",
    "#         477.77777778,  542.22222222,  606.66666667,  671.11111111,\n",
    "#         735.55555556,  800.        ])\n",
    "gpas = np.linspace(data['gpa'].min(), data['gpa'].max(), 10)\n",
    "print gpas\n",
    "# array([ 2.26      ,  2.45333333,  2.64666667,  2.84      ,  3.03333333,\n",
    "#         3.22666667,  3.42      ,  3.61333333,  3.80666667,  4.        ])\n",
    "\n",
    "\n",
    "# enumerate all possibilities\n",
    "combos = pd.DataFrame(cartesian([gres, gpas, [1, 2, 3, 4], [1.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1    2    3\n",
      "0    220.0  2.260000  1.0  1.0\n",
      "1    220.0  2.260000  2.0  1.0\n",
      "2    220.0  2.260000  3.0  1.0\n",
      "3    220.0  2.260000  4.0  1.0\n",
      "4    220.0  2.453333  1.0  1.0\n",
      "5    220.0  2.453333  2.0  1.0\n",
      "6    220.0  2.453333  3.0  1.0\n",
      "7    220.0  2.453333  4.0  1.0\n",
      "8    220.0  2.646667  1.0  1.0\n",
      "9    220.0  2.646667  2.0  1.0\n",
      "10   220.0  2.646667  3.0  1.0\n",
      "11   220.0  2.646667  4.0  1.0\n",
      "12   220.0  2.840000  1.0  1.0\n",
      "13   220.0  2.840000  2.0  1.0\n",
      "14   220.0  2.840000  3.0  1.0\n",
      "15   220.0  2.840000  4.0  1.0\n",
      "16   220.0  3.033333  1.0  1.0\n",
      "17   220.0  3.033333  2.0  1.0\n",
      "18   220.0  3.033333  3.0  1.0\n",
      "19   220.0  3.033333  4.0  1.0\n",
      "20   220.0  3.226667  1.0  1.0\n",
      "21   220.0  3.226667  2.0  1.0\n",
      "22   220.0  3.226667  3.0  1.0\n",
      "23   220.0  3.226667  4.0  1.0\n",
      "24   220.0  3.420000  1.0  1.0\n",
      "25   220.0  3.420000  2.0  1.0\n",
      "26   220.0  3.420000  3.0  1.0\n",
      "27   220.0  3.420000  4.0  1.0\n",
      "28   220.0  3.613333  1.0  1.0\n",
      "29   220.0  3.613333  2.0  1.0\n",
      "..     ...       ...  ...  ...\n",
      "370  800.0  2.646667  3.0  1.0\n",
      "371  800.0  2.646667  4.0  1.0\n",
      "372  800.0  2.840000  1.0  1.0\n",
      "373  800.0  2.840000  2.0  1.0\n",
      "374  800.0  2.840000  3.0  1.0\n",
      "375  800.0  2.840000  4.0  1.0\n",
      "376  800.0  3.033333  1.0  1.0\n",
      "377  800.0  3.033333  2.0  1.0\n",
      "378  800.0  3.033333  3.0  1.0\n",
      "379  800.0  3.033333  4.0  1.0\n",
      "380  800.0  3.226667  1.0  1.0\n",
      "381  800.0  3.226667  2.0  1.0\n",
      "382  800.0  3.226667  3.0  1.0\n",
      "383  800.0  3.226667  4.0  1.0\n",
      "384  800.0  3.420000  1.0  1.0\n",
      "385  800.0  3.420000  2.0  1.0\n",
      "386  800.0  3.420000  3.0  1.0\n",
      "387  800.0  3.420000  4.0  1.0\n",
      "388  800.0  3.613333  1.0  1.0\n",
      "389  800.0  3.613333  2.0  1.0\n",
      "390  800.0  3.613333  3.0  1.0\n",
      "391  800.0  3.613333  4.0  1.0\n",
      "392  800.0  3.806667  1.0  1.0\n",
      "393  800.0  3.806667  2.0  1.0\n",
      "394  800.0  3.806667  3.0  1.0\n",
      "395  800.0  3.806667  4.0  1.0\n",
      "396  800.0  4.000000  1.0  1.0\n",
      "397  800.0  4.000000  2.0  1.0\n",
      "398  800.0  4.000000  3.0  1.0\n",
      "399  800.0  4.000000  4.0  1.0\n",
      "\n",
      "[400 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print combos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Recreate the dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# recreate the dummy variables\n",
    "\n",
    "# keep only what we need for making predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prestige1=np.linspace(data['Prestige_1'].min(),data['Prestige_1'].max(),10)\n",
    "prestige2=np.linspace(data['Prestige_2'].min(),data['Prestige_2'].max(),10)\n",
    "prestige3=np.linspace(data['Prestige_3'].min(),data['Prestige_3'].max(),10)\n",
    "intercept2=np.linspace(data['intercept'].min(),data['intercept'].max(),10)\n",
    "#are these treated the same way even if binary? need to find out...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0     1    2    3         4    5\n",
      "0       220.0  2.26  0.0  0.0  0.000000  1.0\n",
      "1       220.0  2.26  0.0  0.0  0.000000  1.0\n",
      "2       220.0  2.26  0.0  0.0  0.000000  1.0\n",
      "3       220.0  2.26  0.0  0.0  0.000000  1.0\n",
      "4       220.0  2.26  0.0  0.0  0.000000  1.0\n",
      "5       220.0  2.26  0.0  0.0  0.000000  1.0\n",
      "6       220.0  2.26  0.0  0.0  0.000000  1.0\n",
      "7       220.0  2.26  0.0  0.0  0.000000  1.0\n",
      "8       220.0  2.26  0.0  0.0  0.000000  1.0\n",
      "9       220.0  2.26  0.0  0.0  0.000000  1.0\n",
      "10      220.0  2.26  0.0  0.0  0.111111  1.0\n",
      "11      220.0  2.26  0.0  0.0  0.111111  1.0\n",
      "12      220.0  2.26  0.0  0.0  0.111111  1.0\n",
      "13      220.0  2.26  0.0  0.0  0.111111  1.0\n",
      "14      220.0  2.26  0.0  0.0  0.111111  1.0\n",
      "15      220.0  2.26  0.0  0.0  0.111111  1.0\n",
      "16      220.0  2.26  0.0  0.0  0.111111  1.0\n",
      "17      220.0  2.26  0.0  0.0  0.111111  1.0\n",
      "18      220.0  2.26  0.0  0.0  0.111111  1.0\n",
      "19      220.0  2.26  0.0  0.0  0.111111  1.0\n",
      "20      220.0  2.26  0.0  0.0  0.222222  1.0\n",
      "21      220.0  2.26  0.0  0.0  0.222222  1.0\n",
      "22      220.0  2.26  0.0  0.0  0.222222  1.0\n",
      "23      220.0  2.26  0.0  0.0  0.222222  1.0\n",
      "24      220.0  2.26  0.0  0.0  0.222222  1.0\n",
      "25      220.0  2.26  0.0  0.0  0.222222  1.0\n",
      "26      220.0  2.26  0.0  0.0  0.222222  1.0\n",
      "27      220.0  2.26  0.0  0.0  0.222222  1.0\n",
      "28      220.0  2.26  0.0  0.0  0.222222  1.0\n",
      "29      220.0  2.26  0.0  0.0  0.222222  1.0\n",
      "...       ...   ...  ...  ...       ...  ...\n",
      "999970  800.0  4.00  1.0  1.0  0.777778  1.0\n",
      "999971  800.0  4.00  1.0  1.0  0.777778  1.0\n",
      "999972  800.0  4.00  1.0  1.0  0.777778  1.0\n",
      "999973  800.0  4.00  1.0  1.0  0.777778  1.0\n",
      "999974  800.0  4.00  1.0  1.0  0.777778  1.0\n",
      "999975  800.0  4.00  1.0  1.0  0.777778  1.0\n",
      "999976  800.0  4.00  1.0  1.0  0.777778  1.0\n",
      "999977  800.0  4.00  1.0  1.0  0.777778  1.0\n",
      "999978  800.0  4.00  1.0  1.0  0.777778  1.0\n",
      "999979  800.0  4.00  1.0  1.0  0.777778  1.0\n",
      "999980  800.0  4.00  1.0  1.0  0.888889  1.0\n",
      "999981  800.0  4.00  1.0  1.0  0.888889  1.0\n",
      "999982  800.0  4.00  1.0  1.0  0.888889  1.0\n",
      "999983  800.0  4.00  1.0  1.0  0.888889  1.0\n",
      "999984  800.0  4.00  1.0  1.0  0.888889  1.0\n",
      "999985  800.0  4.00  1.0  1.0  0.888889  1.0\n",
      "999986  800.0  4.00  1.0  1.0  0.888889  1.0\n",
      "999987  800.0  4.00  1.0  1.0  0.888889  1.0\n",
      "999988  800.0  4.00  1.0  1.0  0.888889  1.0\n",
      "999989  800.0  4.00  1.0  1.0  0.888889  1.0\n",
      "999990  800.0  4.00  1.0  1.0  1.000000  1.0\n",
      "999991  800.0  4.00  1.0  1.0  1.000000  1.0\n",
      "999992  800.0  4.00  1.0  1.0  1.000000  1.0\n",
      "999993  800.0  4.00  1.0  1.0  1.000000  1.0\n",
      "999994  800.0  4.00  1.0  1.0  1.000000  1.0\n",
      "999995  800.0  4.00  1.0  1.0  1.000000  1.0\n",
      "999996  800.0  4.00  1.0  1.0  1.000000  1.0\n",
      "999997  800.0  4.00  1.0  1.0  1.000000  1.0\n",
      "999998  800.0  4.00  1.0  1.0  1.000000  1.0\n",
      "999999  800.0  4.00  1.0  1.0  1.000000  1.0\n",
      "\n",
      "[1000000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "combos2 = pd.DataFrame(cartesian([gres, gpas,prestige1,prestige2,prestige3,intercept2]))\n",
    "print combos2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# why are there so many rows? does each additional column drastically expand this (e.g. basically exponential growth?)\n",
    "# also, why does column 4 have actual values between 0 and 1 while the others don't "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Make predictions on the enumerated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03989032  0.03989032  0.03989032 ...,  0.89121621  0.89121621\n",
      "  0.89121621]\n"
     ]
    }
   ],
   "source": [
    "output=model_fit.predict(combos2)\n",
    "print output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Interpret findings for the last 4 observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The last 4 observations all seem to indicate an admit value of .89, implying that with those inputs (gre of 800, GPA of 4, and then a score of 1 for all the binaries the likelihood of admit would be .89. However, this result appears skewed, since all of the dummy variables cannot simultaneously be 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Surely there is a better way of doing this/dropping the \"impossible\" values, but I'm not quite following the logic behind the Cartesian distribution so I tried my best above, realizing that the output is somewhat flawed. Looking forward to reviewing this last section in more detail!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Plot the probability of being admitted into graduate school, stratified by GPA and GRE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
